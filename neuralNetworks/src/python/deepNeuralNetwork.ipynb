{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import ProcessData, LinearParameters, apply_activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        config : Dict\n",
    "            config['lp_reg'] = 0,1,2\n",
    "            config['nodes'] = List[int]\n",
    "            config['bias'] = List[Boolean]\n",
    "            config['activators'] = List[str]\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.lp_reg = config['lp_reg']\n",
    "        self.nodes = config['nodes']\n",
    "        self.bias = config['bias']\n",
    "        self.activators = config['activators']\n",
    "        self.L = len(config['nodes']) - 1\n",
    "\n",
    "    def compute_cost(self, y, a, params, lambda_=0.0, eps=1e-8):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        y: array_like\n",
    "        a: array_like\n",
    "        params: class[Parameters]\n",
    "        lambda_: float\n",
    "            Default: 0.0\n",
    "        eps: float\n",
    "            Default: 1e-8\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cost: float\n",
    "        \"\"\"\n",
    "        n = y.shape[1]\n",
    "\n",
    "        # Compute regularization term\n",
    "        R = 0\n",
    "        for param in params.values():\n",
    "            R += np.sum(np.abs(param.w) ** self.lp_reg)\n",
    "        R *= (lambda_ / (2 * n))\n",
    "\n",
    "        # Compute unregularized cost\n",
    "        J = (-1 / n) * (np.sum(y * np.log(a + eps)) +\n",
    "                        np.sum((1 - y) * np.log(1 - a + eps)))\n",
    "\n",
    "        cost = float(np.squeeze(J + R))\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def forward_propagation(self, x, params):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array_like\n",
    "        params : Dict[class[Parameters]]\n",
    "            params[l].w = Weights\n",
    "            params[l].bias = Boolean\n",
    "            params[l].b = Bias\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cache = Dict[arrau_like]\n",
    "            cache['a'] = a\n",
    "            cache['dg'] = dg\n",
    "\n",
    "        \"\"\"\n",
    "        # Initialize dictionaries\n",
    "        a = {}\n",
    "        dg = {}\n",
    "\n",
    "        a[0], dg[0] = apply_activation(x, self.activators[0])\n",
    "\n",
    "        for l in range(1, self.L + 1):\n",
    "            z = params[l].forward(a[l - 1])\n",
    "            a[l], dg[l] = apply_activation(z, self.activators[l])\n",
    "\n",
    "        cache = {'a': a, 'dg': dg}\n",
    "        return cache\n",
    "\n",
    "    def backward_propagation(self, y, params, cache):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        y : array_like\n",
    "        params : Dict[class[Parameters]]\n",
    "            params[l].w = Weights\n",
    "            params[l].bias = Boolean\n",
    "            params[l].b = Bias\n",
    "        cache : Dict[array_like]\n",
    "            cache['a'] : array_like\n",
    "            cache['dg'] : array_like\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        # Retrieve cache\n",
    "        a = cache['a']\n",
    "        dg = cache['dg']\n",
    "\n",
    "        # Initialize differentials along the network\n",
    "        delta = {}\n",
    "        delta[self.L] = (a[self.L] - y) / y.shape[1]\n",
    "\n",
    "        for l in reversed(range(1, self.L + 1)):\n",
    "            delta[l - 1] = dg[l- 1] * params[l].backward(delta[l], a[l - 1])\n",
    "\n",
    "    def update_parameters(self, params, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        params : Dict[class[Parameters]]\n",
    "            params[l].w = Weights\n",
    "            params[l].bias = Boolean\n",
    "            params[l].b = Bias\n",
    "        learning_rate : float\n",
    "            Default : 0.01\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        for param in params.values():\n",
    "            param.update(learning_rate)\n",
    "\n",
    "    def fit(self, x, y, learning_rate=0.01, lambda_=0.0, num_iters=10000):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array_like\n",
    "        y : array_like\n",
    "        learning_rate : float\n",
    "            Default : 0.1\n",
    "        lambda_ : float\n",
    "            Default : 0.0\n",
    "        num_iters : int\n",
    "            Default : 10000\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        costs : List[floats]\n",
    "        params : class[Parameters]\n",
    "        \"\"\"\n",
    "        # Initialize parameters per layer\n",
    "        params = {}\n",
    "        for l in range(1, self.L + 1):\n",
    "            params[l] = LinearParameters(\n",
    "                (self.nodes[l], self.nodes[l - 1]), self.bias[l])\n",
    "\n",
    "        costs = []\n",
    "        for i in range(num_iters):\n",
    "            cache = self.forward_propagation(x, params)\n",
    "            cost = self.compute_cost(y, cache['a'][self.L], params, lambda_)\n",
    "            costs.append(cost)\n",
    "            self.backward_propagation(y, params, cache)\n",
    "            self.update_parameters(params, learning_rate)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'Cost after iteration {i}: {cost}')\n",
    "\n",
    "        return costs, params\n",
    "\n",
    "    def evaluate(self, x, params):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array_like\n",
    "        params : class[Parameters]\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : array_like\n",
    "        \"\"\"\n",
    "        cache = self.forward_propagation(x, params)\n",
    "        a = cache['a'][self.L]\n",
    "        predictions = (~(a < 0.5)).astype(int)\n",
    "        return predictions\n",
    "\n",
    "    def accuracy(self, x, y, params):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array_like\n",
    "        y : array_like\n",
    "        params : class[Parameters]\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        accuracy : float\n",
    "        \"\"\"\n",
    "        predictions = self.evaluate(x, params)\n",
    "        aux = np.abs(predictions - y)\n",
    "        accuracy = 1 - np.sum(aux) / y.shape[1]\n",
    "\n",
    "        return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = Path('data/housepricedata.csv')\n",
    "df = pd.read_csv(csv)\n",
    "dataset = df.values\n",
    "x = dataset[:, 0:10]\n",
    "y = dataset[:, 10].reshape(-1, 1)\n",
    "data = ProcessData(x.T, y.T, 0.15, 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693150024228287\n",
      "Cost after iteration 1000: 0.6930056724734572\n",
      "Cost after iteration 2000: 0.2323146873195952\n",
      "Cost after iteration 3000: 0.20807794045187175\n",
      "Cost after iteration 4000: 0.19673190158839213\n",
      "Cost after iteration 5000: 0.18219621383209497\n",
      "Cost after iteration 6000: 0.16708155305067965\n",
      "Cost after iteration 7000: 0.15178306708809583\n",
      "Cost after iteration 8000: 0.13803811502859992\n",
      "Cost after iteration 9000: 0.12729526477250894\n",
      "The dev accuracy: 0.904109589041096\n",
      "The test accuracy: 0.8995433789954338\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'lp_reg' : 2,\n",
    "    'nodes' : [10, 32, 8, 1],\n",
    "    'bias' : [False, True, True, True],\n",
    "    'activators' : ['linear', 'relu', 'relu', 'sigmoid']\n",
    "}\n",
    "\n",
    "config_1 = {\n",
    "        'lp_reg' : 2,\n",
    "        'nodes' : [10, 32, 32, 1],\n",
    "        'bias' : [False, True, True, True],\n",
    "        'activators' : ['linear', 'relu', 'relu', 'sigmoid']\n",
    "    }\n",
    "\n",
    "model = NeuralNetwork(config)\n",
    "costs, params = model.fit(data.train['x'], data.train['y'], 0.05, 0.03)\n",
    "dev_acc = model.accuracy(data.dev['x'], data.dev['y'], params)\n",
    "print(f'The dev accuracy: {dev_acc}')\n",
    "test_acc = model.accuracy(data.test['x'], data.test['y'], params)\n",
    "print(f'The test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import Model, Input\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "train = {'x': x_train, 'y': y_train}\n",
    "test = {'x': x_test, 'y': y_test}\n",
    "mu = np.mean(train['x'], axis=0, keepdims=True)\n",
    "var = np.var(train['x'], axis=0, keepdims=True)\n",
    "eps = 1e-8\n",
    "train['x'] = (train['x'] - mu) / np.sqrt(var + eps)\n",
    "test['x'] = (test['x'] - mu) / np.sqrt(var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 16:06:15.928302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define network layout\n",
    "input_layer = Input(shape=(10,))\n",
    "hidden_layer_1 = Dense(\n",
    "    32,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    bias_initializer='zeros'\n",
    ")(input_layer)\n",
    "hidden_layer_2 = Dense(\n",
    "    32,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    bias_initializer='zeros'\n",
    ")(hidden_layer_1)\n",
    "output_layer = Dense(\n",
    "    1,\n",
    "    activation='sigmoid',\n",
    "    kernel_initializer='he_normal',\n",
    "    bias_initializer='zeros'\n",
    ")(hidden_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the deisred model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "hist = model.fit(\n",
    "    train['x'],\n",
    "    train['y'],\n",
    "    batch_size=32,\n",
    "    epochs=150,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.3627 - accuracy: 0.8904 - 36ms/epoch - 4ms/step\n",
      "Test Loss: 0.3627116084098816\n",
      "Test Accuracy: 0.8904109597206116\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the model\n",
    "test_scores = model.evaluate(test['x'], test['y'], verbose=2)\n",
    "print(f'Test Loss: {test_scores[0]}')\n",
    "print(f'Test Accuracy: {test_scores[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "59f55f30c9dc85cce51186cb7fbf66a43055ec24d22f5e7a7a56e9de101d7d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
